
https://goquiz.github.io/


https://cloud.tencent.com/developer/news/629972



1.Tomcat等生成日志文件。
2.Filebeat检测日志文件更新。
3.Logstash接收Filebeat传输过来的日志。
4.Elasticsearch接收Logstash传输过来的日志。
5.Kibana展示。


1.Tomcat等生成日志文件。
2.Filebeat检测日志文件更新。
3.Redis等接收Filebeat传输过来的日志。
4.Logstash从Redis中读取消息队列。
5.Elasticsearch接收Logstash传输过来的日志。
6.Kibana展示。


1.Tomcat等生成日志文件。
2.Logback传输日志到消息对列。
3.Redis等接收Filebeat传输过来的日志。
4.Logstash从Redis中读取消息队列。
5.Elasticsearch接收Logstash传输过来的日志。
6.Kibana展示。


日志记录

1.1 Elasticsearch
开源分布式搜索引擎，提供存储、分析、搜索功能。特点：分布式、基于reasful风格、支持海量高并发的准实时搜索场景、稳定、可靠、快速、使用方便等。接收搜集的海量结构化日志数据，并提供给kibana查询分析。
1.2 Logstash
开源日志搜集、分析、过滤框架，支持多种数据输入输出方式。 用于收集日志，对日志进行过滤形成结构化数据，并转发到elasticsearch中。
1.3 Kibana
开源日志报表系统，对elasticsearch以及logstash有良好的web页面支持。对elasticsearch提供的数据进行分析展示。
1.4 Filebeat
Filebeat是一个日志文件托运工具，在你的服务器上安装客户端后，filebeat会监控日志目录或者指定的日志文件，追踪读取这些文件（追踪文件的变化，不停的读）


第三方框架

基于urfave/negroni实现无侵入的中间件模块

选用gorilla/mux实现接口路由定义

基于gorilla/schema实现接口参数解析

选用asaskevich/govalidator实现接口参数校验

选用uber-go/zap实现应用日志打印

基于natefinch/lumberjack实现日志切割

选用jmoiron/sqlx实现数据存取模块

基于Rican7/retry实现必要的重试逻辑

应用相关

对于接口返回给客户端的数据，个人认为越简单越好维护。正常情况好说，坑主要出现在对于错误情况的处理，尤其是针对需要和多个系统交互的服务而言。KISS原则在这里是非常必要的，这能极大减轻后期维护的成本，所以这也是我接下来要坚持的，极简原则。

日志相关

在不影响应用性能的前提下，日志是多多益善的，这会非常便于后期调查各类问题。但是如何恰当的打印日志，需要对后台开发有较深的理解，并且也要懂得一定的运维知识，所以这也是我们踩坑最多的地方。

关键点的定义：考虑到不同人的理解程度不一，于是我抽象出了几个关键点。主要分为接口access，请求redis，请求db，请求第三方接口等，这几个点都是调用封装好的函数实现的。因此在开发过程中可以避免日志未打印的问题。

日志过多的问题：为方便问题查询，最初我们是把这些关键点的日志都入了ELK，但是后来发现日志量过大，kibana渲染数据尤其慢，以致于运维只开放了最近三天的日志，于是我们决定只保留了接口access日志。但是这又加大了调查问题的难度，后面我会简单介绍解决这个问题的方案。

日志切割的问题：最初因为没有发现合适的切割库，于是引入了logrotate来做日志切割。开始时用的是copytruncate模式，后来运维发现磁盘io在高峰期会告警，于是改用了create模式解决了这个问题，通过改进应用支持SIGHUP来reopen日志实现的。不过现在已改为应用自己切割日志了，蛮稳定的。

TraceID的引入：为了更有效的调查问题，接口返回数据增加了TraceID消息头。客户端有错误日志上报机制，若接口返回出错则会带上这个TraceID。通过这种方式，就能在ELK中查询到对应的这个请求相关日志。后期计划会弃用kibana，开启关键点日志。

监控相关

最初是基于kibana来做应用监控，后期发现kibana渲染效率过低，于是就调研并引入了prometheus/grafana实现了nginx、golang及php等应用的相关监控。目前已经搭好了框架，只需要再细化监控指标就可以考虑接入告警系统了。

关键点的定义：与日志类似，我抽象了几个关键点，包括服务接口、lru、redis、db及第三方服务的请求次数与延时分布，相关错误次数的统计。定义好合适的服务等级协议（SLA）以及Apdex（Application Performance Index） score。

自动服务发现：最初是通过修改配置来实现监控服务的增删，后来引入了consul实现自动服务发现，这也可以更好保证监控数据的正确。

稳定高效：prometheus是通过pull的方式获取监控数据的，因此即便挂了不会对应用有任何影响。grafana相对于kibana则异常高效，渲染7天的数据只是毫秒级，而kibana则极大可能会超时导致渲染不出。

有一句话说得好，“no measurement no improvement”。不管我们是改进应用逻辑还是性能，如果没有度量或监控，就无法做好优化，或者说即便优化了也无法自证。这会是我一直推崇的信念，也已在我们的线上环境得到无数次验证，很多线上问题也都是通过这个监控系统发现的。


日志建议用udp协议发到内网的 rsyslog 服务器，分布式日志管理解决方案



监控链 


前一段时间参加了优化一个老的计费系统，学习了一些高并发下做余额扣减的常用手段，也做了一些尝试，因此在这里总结记录一下。

问题描述
对于一个计费系统来说，并发问题事实上分为两类，一类是应用并发高，也就是纯粹的用户量大，访问量多，这类问题和一般的高并发问题没有区别，用分布式等手段就可以解决；另外一类问题则是一般分布式手段无法解决的用户高并发问题，也是本文要着重说的。
这类问题源自对某些高频账号，大量的并发访问，会导致瓶颈首先出现在某些数据库记录上，大量操作由于无法竞争到数据库的行锁而导致等待，这些等待中的操作又会占用其他资源，最终导致系统不可用。
针对这类问题，下边介绍一些常用的处理办法。

不设置余额字段
由于对于一个稳定的计费来说，一定是会记录计费流水明细的，所以完全可以不设置余额字段，而采用根据流水明细计算的方式来获取余额。
不过这种方法不是万能的，比如拿广告业务的计费系统来说，频率非常高，而每次的金额很小，这时候想通过计算求和去算余额，显然是不现实的。

合并与拆分
这是两种方式，因为有一些相似之处，都是要降低对单条数据库记录的访问压力，所以也就放到一起说了。
合并，就是对单个账号的数次请求作合并处理，再往数据库写，这样就等于降低了数倍的压力。
拆分，则是把一个主账号拆分成数个子账号，然后把请求分配到各个子账号上，这样单个账号的压力就小了。然后再用其他手段把子账号的数据合并成主账号数据，返回给用户。

减少行锁占用时间
这是个代码层面的优化，前面说了，高频账号之所以会导致系统的性能问题，就是因为要竞争行锁，所以，如果我们能减少每次请求占用行锁的时间，系统性能也就会大幅度提升了。
所以，首先，要尽量加快从获取行锁到事务提交这个阶段的运行速度，将不必要的操作，尤其是一些耗时的操作，放到其他地方执行，比如获取行锁之前或者事务以外。
然后，尽量避免用

select ... for update
的方式去获取行锁，二是采用下面这种方式：

update xxx set amount=amount-1 where id=x and amount>=1
如果业务层面允许余额扣减成负数的话，就可以不使用where条件中对金额的校验；否则就需要在将要把余额扣成负数时不去更新数据库，并在程序中返回异常。

限流
既然高频账号是单账号的并发达到一定程度后才会导致系统的性能问题，所以我们就可以强制控制这个并发量，使它永远保持在系统可接受的范围内。

缓存
缓存也是一个常用的解决高频账号的方法，在缓存中对余额作操作，然后定时向数据库内同步。

上边介绍了很多方法，当然每一种都会有它的适用条件，也会有其局限性。比如像合并啊，限流啊，实际上都会造成延迟扣费，而在延迟的这个时间段内，可能账户余额已经耗尽，所以如果是严格余额不能为负也不能丢弃记录的业务场景下，其实并不适合用这种方式。
所以说，最重要的还是根据业务场景选择合适的方案。


6.1 给系统加上眼睛：服务端监控要怎么做？
6.2 应用性能管理：用户的使用体验应该如何监控？
6.3 压力测试：怎样设计全链路压力测试平台？
6.4 配置管理：成千上万的配置项要如何管理？
6.5 降级熔断：如何屏蔽非核心系统故障的影响？
6.6 流量控制：高并发系统中我们如何操纵流量？
6.7 面试现场第三期：你要如何准备一场技术面试呢？


阿里关于redis缓存面试真题：
项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？
redis 和 memcached 有什么区别？redis 的线程模型是什么？为什么 redis 单线程却能支撑高并发？
redis 都有哪些数据类型？分别在哪些场景下使用比较合适？
redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？
如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？
redis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？
redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？
了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？
如何保证缓存与数据库的双写一致性？
redis 的并发竞争问题是什么？如何解决这个问题？了解redis 事务的 CAS 方案吗？
生产环境中的 redis 是怎么部署的？


阿里关于分布式面试真题：
说一下的 dubbo 的工作原理？注册中心挂了可以继续通信吗？说说一次 rpc 请求的流程？
dubbo 支持哪些通信协议？支持哪些序列化协议？说一下Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？
dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？
dubbo 的 spi 思想是什么？
如何基于 dubbo 进行服务治理、服务降级、失败重试以及超时重试？
分布式服务接口的幂等性如何设计（比如不能重复扣款）？
分布式服务接口请求的顺序性如何保证？
如何自己设计一个类似 Dubbo 的 RPC 框架？
zookeeper 都有哪些使用场景？
一般实现分布式锁都有哪些方式？使用 redis 如何设计分布式锁？使用 zk 来设计分布式锁可以吗？这两种分布式锁的实现方式哪种效率比较高？
分布式事务了解吗？你们是如何解决分布式事务问题的？面试官心理分析
集群部署时的分布式 session 如何实现？



阿里关于微服务面试真题：
什么是 Spring Cloud？
使用 Spring Cloud 有什么优势？
服务注册和发现是什么意思？Spring Cloud 如何实现？
负载平衡的意义什么？
什么是 Hystrix？它如何实现容错？
什么是 Hystrix 断路器？我们需要它吗？
什么是 Netflix Feign？它的优点是什么？
什么是 Spring Cloud Bus？我们需要它吗？



脱离了业务的系统架构

选择当时最优的选择




要点有如下几项：

1、垂直分层：DNS层、跨机房部署、LVS+Nginx负载均衡，vanish+共享存储实现动静分离，Nginx后挂载N台服务器集群，服务器集群后挂载微服务化、微服务后挂载数据库分库分表+消息队列+任务调度，最后端挂载数据集群负责数据的统一归档+流计算+异步批处理

2、水平分区：根据业务划分业务线，每个业务线中设计分区键，根据userNo设计用户隔离，根据IP地址设计地区隔离，根据用户级别设计级别隔离，根据操作日期设计时间隔离，根据关键key进行hash散列，然后考虑一下分区的扩容、缩容、灾备、监控

3、数据同步，跨机房跨集群的困难点在于数据同步，有三种做法：

3.1）不同步，任由各子集群在自己的业务范围内运行

3.2）汇总集群，建立一个统一的数据汇总集群（如Hadoop\Spark\Kylin等），将数据汇总到统一的大数据集群中，再进行统计、汇总、运算等。缺点是会有时间差，短须5分钟，长须一天以上

3.3）远程数据同步，通过开源框架实现多个数据库的同步，例如阿里的otter，底层为canal，模拟mysql的从库，实现日志解析并数据库入库，时间差较短，如果网络没有太大问题，可在秒级完成数据同步。数据同步冲突算法有两种：单向回环补救、时间交集补救。一般推荐使用单向回环补救，即：如果发现数据库A与数据库B的同步时间差大于某个数值，则根据pk查询最新记录同步到数据库中。而另一种算法时间交集补救，是根据“时间交集”的定义，获得双方数据库的“时间交叉的操作”清单，然后根据此清单执行单向回环补救。此方法缺点为：a)开源版本中仅有单向回环补救;b)只支持mysql->mysql同步或者mysql->oracle同步。



集齐以上三件，基本上百万级并发就轻松搞定了。然后需要注意一些细节：

1）集群与集群之间要实现从入口开始的严格隔离，即DNS层->LVS层->Nginx层完全隔离

2）数据库的链接数是重要资源，一个mysql数据库可以提供1000链接，也就是说，按照50链接/每机器来计算，最多链接20个实例，硬上一下超不过30台。因此数据库层的分库分表一定要彻彻底底的分开。子集群之间不能互相链接数据库。

3）一些关键业务可以在缓存中操作，建议采用redis缓存。而memcache死机后数据丢失，mongodb功能尚不完善。redis的安全机制一定要做好，千万不能丢数据。缓存到数据库的存储可以采用计数形式，每隔N次操作存一次数据库，可以线性降低数据库压力

4）数据库只使用简单的存取功能，所有业务功能在代码层实现，DBA推荐的分区、分存储、存储过程等功能一般在数据仓库中是有用的，而在实时计算系统中，千万不要采用。否则你会看到你们几百人的开发团队等待一个DBA给你们排期的情况。

5）前端可以做一些小的手段，例如抽奖活动，可以在页面js中直接告诉用户未中奖，而并不通知后台，此为“基础不中奖率”，可以直接过滤掉90%以上的流量。（此功能请与产品团队好好沟通，从性价比上讲，这种小手段不提倡，但是性价比极高。）

6）消息队列系统建议采用一些堆积能力较强的系统，如:rocketmq,rabbit等，建议rocketmq，消息堆积能力之强，单机堆积上亿条。

7）日志系统建议kafka，日志系统之后可以增加storm,hdfs,logstash等配套设施

8）网卡流量问题需要严重关注，经常出现的问题是：在某个活动之间，redis网卡流量打满，导致redis无法访问，整个业务暂停。需要网络部门对公司内部的服务器路由有准确估算，出现分值之后可以妥善定位问题并修复，日常工作中也要做好规划，提前做好准备。

9）老生常谈的：断路器、限流、自动降级。断路器是指在RPC的客户端中实现如下功能：如果发现该断路器访问服务端在10秒内访问超过50次且失败率高于50%，则中断该断路器的访问10秒钟，以保护下游系统。自动降级就是：如果发生问题，自动切换到备用程序上，如报错、如访问redis失败改访问DB等。限流就是在RPC的服务端中实现如下功能：对每个IP、每个token进行限制，通过令牌桶算法，每个时间段只允许指定数量的服务通过，否则就拒绝服务调用。一般断路器使用hystrix，自动降级可以自行实现，也可以用hystrix的配套设施实现，限流比较简单自行实现即可。




这种级别的并发已经不是简单的分片就能解决了。是的，综合了以上文章提到的所有点，而非仅数据分片，这种级别并发需要从流量入口点到业务结束点每个环节都进行考虑。



redis上100k很正常，如果不考虑场景pipeline上200k也不是问题。怎么说呢，我司有专门研究redis的部门，但想尽一切办法没能在生产环境实现单进程100k(采用的方法含：使用物理机、升级CPU和SSD硬盘、建立网络专线、操作系统内核调整、redis参数调整、rediskey-value优化等等，均是“差一点能够到，但就是达不到”)，最终采用的是对redis二次改造升级的方案，记得16年双十一的时候是峰值83万链接，并发数过千万



但你又要保证性能的同时又想让redis做到数据安全这个有点强人所难了（请问这里怎么做到鱼与熊掌兼得的）。从来没有100%安全的系统，再怎么安全的系统，拔了电源肯定会丢数据。我司采用的方式是redis按业务与交易类型分子集群，每个集群一主双从，主从复制，磁盘同步刷盘，无热切换。此种方案在redis层面上是性能最高、数据最安全、但是会有故障后可读不可写的问题。原因是，在设计时，要求中间件层与其他层要隔离出明确界限，不因“业务层发现redis不可用后的补救措施”干扰到中间件层的设计。而业务层如果发现redis不可用，会在业务层根据自行处理。这个方案的原则是：1）中间件层明确与业务层隔离；2）中间件层最大可能保证基础设施可用；3）基础设施不可用的情况下，异常由业务层处理；(PS : 这套系统上线的时候，redis最高版本为2.8，后期虽然redis有了3.0和4.0，但是因为没有遇到新的不能解决的问题，所以没有升级计划)



熔断不说了，系统的降级缓存没响应直接透到db这个确认可行？想过流量过来后的后果么。降级处理有很多方式的，如：透到DB\直接异常\返回降级信息等，不一定非得DB。redis崩溃后的缓存常见问题：缓存穿透、缓存雪崩、缓存过期，网上的处理方法很多的，这类问题曾经是大事，但现在已经属于科普性质的小知识点了，按着规矩做就行。



https://zhuanlan.zhihu.com/p/38636111




goframe 挺好用的。
goframe 对标 Python 中的 Django
 gin 对标 Flask
 
 
 https://www.jetbrains.com/lp/devecosystem-2020/go/
